{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Model Development\n",
    "\n",
    "##  Goal: Predict Conversion & Optimize Marketing Strategies\n",
    "\n",
    "### ðŸ“– Overview:\n",
    "In this notebook, we will develop machine learning models to predict **conversion rates** and optimize **marketing strategies**. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries & Load Data\n",
    "We will load the dataset (../data/feature_engineered.csv) and check its structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CustomerID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Income</th>\n",
       "      <th>CampaignChannel</th>\n",
       "      <th>CampaignType</th>\n",
       "      <th>AdSpend</th>\n",
       "      <th>ClickThroughRate</th>\n",
       "      <th>ConversionRate</th>\n",
       "      <th>WebsiteVisits</th>\n",
       "      <th>PagesPerVisit</th>\n",
       "      <th>TimeOnSite</th>\n",
       "      <th>SocialShares</th>\n",
       "      <th>EmailOpens</th>\n",
       "      <th>EmailClicks</th>\n",
       "      <th>PreviousPurchases</th>\n",
       "      <th>LoyaltyPoints</th>\n",
       "      <th>AdvertisingPlatform</th>\n",
       "      <th>AdvertisingTool</th>\n",
       "      <th>Conversion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8000</td>\n",
       "      <td>56</td>\n",
       "      <td>Female</td>\n",
       "      <td>136912</td>\n",
       "      <td>Social Media</td>\n",
       "      <td>Awareness</td>\n",
       "      <td>6497.870068</td>\n",
       "      <td>0.043919</td>\n",
       "      <td>0.088031</td>\n",
       "      <td>0</td>\n",
       "      <td>2.399017</td>\n",
       "      <td>7.396803</td>\n",
       "      <td>19</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>688</td>\n",
       "      <td>IsConfid</td>\n",
       "      <td>ToolConfid</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8001</td>\n",
       "      <td>69</td>\n",
       "      <td>Male</td>\n",
       "      <td>41760</td>\n",
       "      <td>Email</td>\n",
       "      <td>Retention</td>\n",
       "      <td>3898.668606</td>\n",
       "      <td>0.155725</td>\n",
       "      <td>0.182725</td>\n",
       "      <td>42</td>\n",
       "      <td>2.917138</td>\n",
       "      <td>5.352549</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>3459</td>\n",
       "      <td>IsConfid</td>\n",
       "      <td>ToolConfid</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8002</td>\n",
       "      <td>46</td>\n",
       "      <td>Female</td>\n",
       "      <td>88456</td>\n",
       "      <td>PPC</td>\n",
       "      <td>Awareness</td>\n",
       "      <td>1546.429596</td>\n",
       "      <td>0.277490</td>\n",
       "      <td>0.076423</td>\n",
       "      <td>2</td>\n",
       "      <td>8.223619</td>\n",
       "      <td>13.794901</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>2337</td>\n",
       "      <td>IsConfid</td>\n",
       "      <td>ToolConfid</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8003</td>\n",
       "      <td>32</td>\n",
       "      <td>Female</td>\n",
       "      <td>44085</td>\n",
       "      <td>PPC</td>\n",
       "      <td>Conversion</td>\n",
       "      <td>539.525936</td>\n",
       "      <td>0.137611</td>\n",
       "      <td>0.088004</td>\n",
       "      <td>47</td>\n",
       "      <td>4.540939</td>\n",
       "      <td>14.688363</td>\n",
       "      <td>89</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2463</td>\n",
       "      <td>IsConfid</td>\n",
       "      <td>ToolConfid</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8004</td>\n",
       "      <td>60</td>\n",
       "      <td>Female</td>\n",
       "      <td>83964</td>\n",
       "      <td>PPC</td>\n",
       "      <td>Conversion</td>\n",
       "      <td>1678.043573</td>\n",
       "      <td>0.252851</td>\n",
       "      <td>0.109940</td>\n",
       "      <td>0</td>\n",
       "      <td>2.046847</td>\n",
       "      <td>13.993370</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>4345</td>\n",
       "      <td>IsConfid</td>\n",
       "      <td>ToolConfid</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CustomerID  Age  Gender  Income CampaignChannel CampaignType      AdSpend  \\\n",
       "0        8000   56  Female  136912    Social Media    Awareness  6497.870068   \n",
       "1        8001   69    Male   41760           Email    Retention  3898.668606   \n",
       "2        8002   46  Female   88456             PPC    Awareness  1546.429596   \n",
       "3        8003   32  Female   44085             PPC   Conversion   539.525936   \n",
       "4        8004   60  Female   83964             PPC   Conversion  1678.043573   \n",
       "\n",
       "   ClickThroughRate  ConversionRate  WebsiteVisits  PagesPerVisit  TimeOnSite  \\\n",
       "0          0.043919        0.088031              0       2.399017    7.396803   \n",
       "1          0.155725        0.182725             42       2.917138    5.352549   \n",
       "2          0.277490        0.076423              2       8.223619   13.794901   \n",
       "3          0.137611        0.088004             47       4.540939   14.688363   \n",
       "4          0.252851        0.109940              0       2.046847   13.993370   \n",
       "\n",
       "   SocialShares  EmailOpens  EmailClicks  PreviousPurchases  LoyaltyPoints  \\\n",
       "0            19           6            9                  4            688   \n",
       "1             5           2            7                  2           3459   \n",
       "2             0          11            2                  8           2337   \n",
       "3            89           2            2                  0           2463   \n",
       "4             6           6            6                  8           4345   \n",
       "\n",
       "  AdvertisingPlatform AdvertisingTool  Conversion  \n",
       "0            IsConfid      ToolConfid           1  \n",
       "1            IsConfid      ToolConfid           1  \n",
       "2            IsConfid      ToolConfid           1  \n",
       "3            IsConfid      ToolConfid           1  \n",
       "4            IsConfid      ToolConfid           1  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, StackingClassifier, VotingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import AdaBoostClassifier, ExtraTreesClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"../data/raw_data.csv\")\n",
    "\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversion\n",
      "1    0.8765\n",
      "0    0.1235\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X = df.drop(columns=['Conversion'])  \n",
    "y = df['Conversion']  \n",
    "\n",
    "\n",
    "print(y.value_counts(normalize=True))\n",
    "X = pd.get_dummies(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 6400, Test samples: 1600\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "print(f\"Training samples: {len(X_train)}, Test samples: {len(X_test)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handle Class Imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class imbalance detected. Imbalance ratio: 0.14\n",
      "Moderate imbalance. Consider adjusting class weights in models.\n"
     ]
    }
   ],
   "source": [
    "# Check class imbalance\n",
    "class_counts = np.bincount(y_train)\n",
    "min_samples = np.min(class_counts)\n",
    "max_samples = np.max(class_counts)\n",
    "imbalance_ratio = min_samples / max_samples\n",
    "    \n",
    "if imbalance_ratio < 0.5:  \n",
    "        print(f\"Class imbalance detected. Imbalance ratio: {imbalance_ratio:.2f}\")\n",
    "        if imbalance_ratio < 0.1:\n",
    "            print(\"Severe imbalance. Applying SMOTE...\")\n",
    "            smote = SMOTE(random_state=42)\n",
    "            X_train, y_train = smote.fit_resample(X_train, y_train)\n",
    "        else:\n",
    "            print(\"Moderate imbalance. Consider adjusting class weights in models.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Baseline Model (Logistic Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "**Logistic Regression Performance:**\n",
      "Accuracy: 0.876875\n",
      "F1 Score: 0.9341357405549984\n",
      "Confusion Matrix:\n",
      " [[   6  192]\n",
      " [   5 1397]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.03      0.06       198\n",
      "           1       0.88      1.00      0.93      1402\n",
      "\n",
      "    accuracy                           0.88      1600\n",
      "   macro avg       0.71      0.51      0.50      1600\n",
      "weighted avg       0.84      0.88      0.83      1600\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\oussama\\Downloads\\Marketing_Conversion_Analysis\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "# Evaluation\n",
    "print(\"\\n**Logistic Regression Performance:**\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Advanced Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training RandomForest...\n",
      "Accuracy: 0.8925, F1 Score: 0.9417\n",
      "\n",
      "Training GradientBoost...\n",
      "Accuracy: 0.9025, F1 Score: 0.9459\n",
      "\n",
      "Training XGBoost...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\oussama\\Downloads\\Marketing_Conversion_Analysis\\venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [03:23:34] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9306, F1 Score: 0.9610\n",
      "\n",
      "Training LightGBM...\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 5610, number of negative: 790\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001268 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2305\n",
      "[LightGBM] [Info] Number of data points in the train set: 6400, number of used features: 25\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.876563 -> initscore=1.960273\n",
      "[LightGBM] [Info] Start training from score 1.960273\n",
      "Accuracy: 0.9275, F1 Score: 0.9594\n",
      "\n",
      "Training CatBoost...\n",
      "Accuracy: 0.9394, F1 Score: 0.9658\n",
      "\n",
      "Top 3 Models based on F1 Score: [('CatBoost', (0.939375, 0.9657606777267914)), ('XGBoost', (0.930625, 0.9610115911485775)), ('LightGBM', (0.9275, 0.9593552908199019))]\n"
     ]
    }
   ],
   "source": [
    "models = {\n",
    "    'RandomForest': RandomForestClassifier(),\n",
    "    'GradientBoost': GradientBoostingClassifier(),\n",
    "    'XGBoost': XGBClassifier(use_label_encoder=False, eval_metric='logloss'),\n",
    "    'LightGBM': LGBMClassifier(),\n",
    "    'CatBoost': CatBoostClassifier(verbose=0)\n",
    "}\n",
    "\n",
    "model_performance = {}\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    print(f\"\\nTraining {model_name}...\")\n",
    "    \n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Evaluate\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    \n",
    "    model_performance[model_name] = (accuracy, f1)\n",
    "    \n",
    "    print(f\"Accuracy: {accuracy:.4f}, F1 Score: {f1:.4f}\")\n",
    "\n",
    "# Sort top 3 models\n",
    "top_3_models = sorted(model_performance.items(), key=lambda x: x[1][1], reverse=True)[:3]\n",
    "print(\"\\nTop 3 Models based on F1 Score:\", top_3_models)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Voting Classifier with Top Models\n",
    "Combine the top 3 models into a Voting Classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\oussama\\Downloads\\Marketing_Conversion_Analysis\\venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [03:23:54] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 5610, number of negative: 790\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001819 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2305\n",
      "[LightGBM] [Info] Number of data points in the train set: 6400, number of used features: 25\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.876563 -> initscore=1.960273\n",
      "[LightGBM] [Info] Start training from score 1.960273\n",
      "\n",
      "**Voting Classifier Performance:**\n",
      "Accuracy: 0.93375\n",
      "F1 Score: 0.9627808988764045\n",
      "Confusion Matrix:\n",
      " [[ 123   75]\n",
      " [  31 1371]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.62      0.70       198\n",
      "           1       0.95      0.98      0.96      1402\n",
      "\n",
      "    accuracy                           0.93      1600\n",
      "   macro avg       0.87      0.80      0.83      1600\n",
      "weighted avg       0.93      0.93      0.93      1600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "top_3_model_names = [model[0] for model in top_3_models]\n",
    "top_3_classifiers = [models[model_name] for model_name in top_3_model_names]\n",
    "\n",
    "voting_clf = VotingClassifier(estimators=list(zip(top_3_model_names, top_3_classifiers)), voting='hard')\n",
    "\n",
    "\n",
    "voting_clf.fit(X_train, y_train)\n",
    "y_pred = voting_clf.predict(X_test)\n",
    "\n",
    "# Evaluation\n",
    "print(\"\\n**Voting Classifier Performance:**\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacking Classifier\n",
    "Combine top 3 models into a Stacking Classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\oussama\\Downloads\\Marketing_Conversion_Analysis\\venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [03:24:36] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 5610, number of negative: 790\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000965 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2305\n",
      "[LightGBM] [Info] Number of data points in the train set: 6400, number of used features: 25\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.876563 -> initscore=1.960273\n",
      "[LightGBM] [Info] Start training from score 1.960273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\oussama\\Downloads\\Marketing_Conversion_Analysis\\venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [03:25:15] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\oussama\\Downloads\\Marketing_Conversion_Analysis\\venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [03:25:15] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\oussama\\Downloads\\Marketing_Conversion_Analysis\\venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [03:25:15] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\oussama\\Downloads\\Marketing_Conversion_Analysis\\venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [03:25:16] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\oussama\\Downloads\\Marketing_Conversion_Analysis\\venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [03:25:17] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 4488, number of negative: 632\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000869 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2305\n",
      "[LightGBM] [Info] Number of data points in the train set: 5120, number of used features: 25\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.876563 -> initscore=1.960273\n",
      "[LightGBM] [Info] Start training from score 1.960273\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 4488, number of negative: 632\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000978 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2305\n",
      "[LightGBM] [Info] Number of data points in the train set: 5120, number of used features: 25\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.876563 -> initscore=1.960273\n",
      "[LightGBM] [Info] Start training from score 1.960273\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 4488, number of negative: 632\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.070311 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2305\n",
      "[LightGBM] [Info] Number of data points in the train set: 5120, number of used features: 25\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.876563 -> initscore=1.960273\n",
      "[LightGBM] [Info] Start training from score 1.960273\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 4488, number of negative: 632\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000727 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2305\n",
      "[LightGBM] [Info] Number of data points in the train set: 5120, number of used features: 25\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.876563 -> initscore=1.960273\n",
      "[LightGBM] [Info] Start training from score 1.960273\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of positive: 4488, number of negative: 632\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000861 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2305\n",
      "[LightGBM] [Info] Number of data points in the train set: 5120, number of used features: 25\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.876563 -> initscore=1.960273\n",
      "[LightGBM] [Info] Start training from score 1.960273\n"
     ]
    }
   ],
   "source": [
    "stacking_clf = StackingClassifier(estimators=list(zip(top_3_model_names, top_3_classifiers)))\n",
    "\n",
    "\n",
    "stacking_clf.fit(X_train, y_train)\n",
    "y_pred = stacking_clf.predict(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "**Stacking Classifier Performance:**\n",
      "Accuracy: 0.94125\n",
      "F1 Score: 0.9667844522968198\n",
      "Confusion Matrix:\n",
      " [[ 138   60]\n",
      " [  34 1368]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.70      0.75       198\n",
      "           1       0.96      0.98      0.97      1402\n",
      "\n",
      "    accuracy                           0.94      1600\n",
      "   macro avg       0.88      0.84      0.86      1600\n",
      "weighted avg       0.94      0.94      0.94      1600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluation\n",
    "print(\"\\n**Stacking Classifier Performance:**\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Saved RandomForest to ../models/RandomForest.pkl\n",
      "âœ… Saved GradientBoost to ../models/GradientBoost.pkl\n",
      "âœ… Saved XGBoost to ../models/XGBoost.pkl\n",
      "âœ… Saved LightGBM to ../models/LightGBM.pkl\n",
      "âœ… Saved CatBoost to ../models/CatBoost.pkl\n",
      "âœ… Saved Voting Classifier to ../models/VotingClassifier.pkl\n",
      "âœ… Saved Stacking Classifier to ../models/StackingClassifier.pkl\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import os\n",
    "\n",
    "os.makedirs(\"../models\", exist_ok=True)\n",
    "\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    model_path = f\"../models/{model_name}.pkl\"\n",
    "    joblib.dump(model, model_path)\n",
    "    print(f\"âœ… Saved {model_name} to {model_path}\")\n",
    "\n",
    "\n",
    "voting_clf_path = \"../models/VotingClassifier.pkl\"\n",
    "joblib.dump(voting_clf, voting_clf_path)\n",
    "print(f\"âœ… Saved Voting Classifier to {voting_clf_path}\")\n",
    "\n",
    "\n",
    "stacking_clf_path = \"../models/StackingClassifier.pkl\"\n",
    "joblib.dump(stacking_clf, stacking_clf_path)\n",
    "print(f\"âœ… Saved Stacking Classifier to {stacking_clf_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… Model performance saved as model_performance.pkl!\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(model_performance, \"../models/model_performance.pkl\")\n",
    "\n",
    "print(\"\\nâœ… Model performance saved as model_performance.pkl!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
